<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Jun&#039;s Blog</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Jun&#039;s Blog"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Jun&#039;s Blog"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta property="og:type" content="blog"><meta property="og:title" content="Jun&#039;s Blog"><meta property="og:url" content="https://xuj14.github.io/"><meta property="og:site_name" content="Jun&#039;s Blog"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://xuj14.github.io/img/og_image.png"><meta property="article:author" content="Jun XU"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://xuJ14.github.io"},"headline":"Jun's Blog","image":["https://xuj14.github.io/img/og_image.png"],"author":{"@type":"Person","name":"Jun XU"},"description":""}</script><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/tomorrow-night-bright.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.4.0">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
</head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="Jun&#039;s Blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item is-active" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/xuJ14/xuJ14.github.io.git"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-04-18T19:25:01.000Z" title="2021/4/18 下午3:25:01">2021-04-18</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-04-18T07:26:13.273Z" title="2021/4/18 上午3:26:13">2021-04-18</time></span><span class="level-item">5 minutes read (About 734 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Machine-Learning-Week10/">Machine Learning Week10</a></h1><div class="content"><h1 id="Large-Scale-Machine-Learning"><a href="#Large-Scale-Machine-Learning" class="headerlink" title="Large Scale Machine Learning"></a>Large Scale Machine Learning</h1><h2 id="Gradient-Descent-with-Large-Datasets"><a href="#Gradient-Descent-with-Large-Datasets" class="headerlink" title="Gradient Descent with Large Datasets"></a>Gradient Descent with Large Datasets</h2><h3 id="Learning-with-large-datasets"><a href="#Learning-with-large-datasets" class="headerlink" title="Learning with large datasets"></a>Learning with large datasets</h3><p>如何知道小m（size of dataset）也能产生很好的结果？绘制learning curve（error关于m的曲线）</p>
<p>左图为high variance，说明增加m有助于结果变好；右图为high bias，说明增加m无助于结果变好</p>
<p><img src="https://cdn.jsdelivr.net/gh/xuJ14/ImageHost@latest/images/image-20210409182113679.png" alt="左：high variance；右: high bias"></p>
<h3 id="Stochastic-gradient-descent-随机梯度下降"><a href="#Stochastic-gradient-descent-随机梯度下降" class="headerlink" title="Stochastic gradient descent 随机梯度下降"></a>Stochastic gradient descent 随机梯度下降</h3><p>Batch gradient descent: 前述传统的梯度下降算法。batch意味着每次都要用到所有m个例子</p>
<p>Stochastic gradient descent：每次iteration用1个例子</p>
<ol>
<li><p>Randomly shuffle dataset</p>
</li>
<li><p>Repeat：</p>
<p>for i =1,…, m {   $\theta_j=\theta_j-\alpha(h_{\theta}(x^{(i)})-y^{(i)})x_j^{(i)}$   }</p>
<blockquote>
<p>Note: 和Batch gradient descent不同的是，无需每一步都要计算全部的training example</p>
</blockquote>
</li>
</ol>
<p>并不一定会达到global minimum，最后可能在全局最优附近徘徊。</p>
<p>上述过程重复的次数取决于数据集的大小，一般为10次，若数据集特别大，则1次。</p>
<h3 id="Mini-Batch-gradient-descent"><a href="#Mini-Batch-gradient-descent" class="headerlink" title="Mini-Batch gradient descent"></a>Mini-Batch gradient descent</h3><p>每次iteration用b（mini-batch size）个例子，常用2-100</p>
<p>第i个例子，直到第i+b-1个例子</p>
<p><img src="https://cdn.jsdelivr.net/gh/xuJ14/ImageHost@latest/images/image-20210415223239627.png" alt="mini-batch gradient descent"></p>
<p>只有当have a good vetorized implementation ，mini-batch才能比stochastic表现得更好。（并行运算）</p>
<h3 id="Stochastic-gradient-descent-convergence"><a href="#Stochastic-gradient-descent-convergence" class="headerlink" title="Stochastic gradient descent convergence"></a>Stochastic gradient descent convergence</h3><p>收敛性：</p>
<ul>
<li><img src="https://cdn.jsdelivr.net/gh/xuJ14/ImageHost@latest/images/image-20210416223947732.png" alt="Algorithm"></li>
<li>更小的学习速率学习曲线更平滑，有可能会得到slightly better结果。（cost关于no. of iteration 的曲线）</li>
<li>增加1000这个数值，会使得曲线更加平滑</li>
<li>如果学习曲线在上升，就要用更小的α</li>
<li>如果学习曲线几乎在一个水平上，那么就需要增加特征等</li>
<li>关于学习速率的选择：<ul>
<li>Learning rate α is typically held constant 在随机梯度下降中</li>
<li>Can slowly decrease α over time if we want θ to converge. （例如：$\alpha=\frac{const1}{iteration Number+const2}$）<ul>
<li>但是这里，两个参数的调整tune会很费时间，所以很少采用这种方法</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="Advanced-Topics"><a href="#Advanced-Topics" class="headerlink" title="Advanced Topics"></a>Advanced Topics</h2><h3 id="Online-Learning"><a href="#Online-Learning" class="headerlink" title="Online Learning"></a>Online Learning</h3><ul>
<li><p>连续的数据流：用户进入离开</p>
</li>
<li><p>$p(y=1|x;\theta)$其中x表示价格，可以用logistic regression或者神经网络</p>
</li>
<li><p>这里考虑逻辑回归：</p>
<p>Repeat forever {</p>
<p>​    Get (x,y) corresponding to user.</p>
<p>​    Update θ using (x,y):</p>
<p>​        $\theta_j:=\theta_j-\alpha(h_{\theta}(x)-y)x_j$           (j=0, …, n)</p>
<p>}</p>
</li>
<li><p>这个算法可以用于学习用户喜好</p>
<ul>
<li>Choosing special offers to show user</li>
<li>Customized selection of news articles</li>
<li>product recommendation/search</li>
</ul>
</li>
</ul>
<h3 id="Map-reduce-and-data-parallelism"><a href="#Map-reduce-and-data-parallelism" class="headerlink" title="Map reduce and data parallelism"></a>Map reduce and data parallelism</h3><p>Map reduce 可以处理更多数据。思想来自于Jeffrey Dean和Sanjay Ghemawat。summation over the training set。即并行处理</p>
<ul>
<li>神经网络也同样可以并行计算前向和后向propagation</li>
<li>有时只需要向量化实现算法，不需要多核并行</li>
<li>Hadoop是开源map reduce</li>
<li>由于并行的latency，速度会少于N倍 的单核心</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-04-04T14:40:50.000Z" title="2021/4/4 上午10:40:50">2021-04-04</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-04-04T15:04:21.407Z" title="2021/4/4 上午11:04:21">2021-04-04</time></span><span class="level-item">a minute read (About 121 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Reading-List/"> </a></h1><div class="content"><h1 id="1-Machine-Learning"><a href="#1-Machine-Learning" class="headerlink" title="1. Machine Learning"></a>1. Machine Learning</h1><h2 id="Step-1"><a href="#Step-1" class="headerlink" title="Step 1"></a>Step 1</h2><ul>
<li>[ ] Hands-On Machine learning with Scikit-Learn and Tensorflow</li>
<li>[ ] Python Machine Learning. Sebastian Raschka</li>
<li>[ ] Introduction to Statistical Learning with R</li>
<li>[ ] 【参考书】机器学习. 周志华</li>
</ul>
<h2 id="Step-2"><a href="#Step-2" class="headerlink" title="Step 2"></a>Step 2</h2><ul>
<li>[ ] 训练平台：Kaggle，天池大数据竞赛</li>
<li>[ ] Scikit-learn: machine learning in Python</li>
</ul>
<h2 id="Step-3"><a href="#Step-3" class="headerlink" title="Step 3"></a>Step 3</h2><ul>
<li>[ ] Deeplearning.ai —— Coursera</li>
<li>[ ] Deep learning - by Ian GoodFellow</li>
</ul>
<h2 id="Step-4"><a href="#Step-4" class="headerlink" title="Step 4"></a>Step 4</h2><ul>
<li>[ ] Elements of Statistical Learning</li>
<li>[ ] 统计学习基础</li>
<li>[ ] 订阅arxiv</li>
<li>[ ] 关注顶会：ICML/NIPS/KDD</li>
</ul>
<h1 id="2-Financial-Engineering"><a href="#2-Financial-Engineering" class="headerlink" title="2. Financial Engineering"></a>2. Financial Engineering</h1><p><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/302531501/answer/534780501">金融工程专业需要哪些数学基础？ - 经管之家的回答 - 知乎</a> </p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-04-04T14:24:26.000Z" title="2021/4/4 上午10:24:26">2021-04-04</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-04-04T14:26:05.151Z" title="2021/4/4 上午10:26:05">2021-04-04</time></span><span class="level-item">a few seconds read (About 93 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/How-to-Read-Papers/">How to Read Papers</a></h1><div class="content"><h1 id="How-to-Read-Papers"><a href="#How-to-Read-Papers" class="headerlink" title="How to Read Papers?"></a>How to Read Papers?</h1><h2 id="Resources"><a href="#Resources" class="headerlink" title="Resources"></a>Resources</h2><ul>
<li>Arxiv</li>
<li>Blog Posts</li>
<li>Text Books</li>
</ul>
<h2 id="Prepare"><a href="#Prepare" class="headerlink" title="Prepare"></a>Prepare</h2><ul>
<li>列出待读论文，每一篇列一行，表示从0-100的阅读进度</li>
<li>如果有论文不是想要的，就删掉</li>
<li>如果有新的论文就加进来</li>
</ul>
<h2 id="Methods"><a href="#Methods" class="headerlink" title="Methods"></a>Methods</h2><ul>
<li>第一遍：只看标题，摘要，图表</li>
<li>第二遍：前言，结语，图表</li>
<li>第三遍：论文主体</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-04-04T14:16:35.000Z" title="2021/4/4 上午10:16:35">2021-04-04</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-04-08T16:26:08.822Z" title="2021/4/8 下午12:26:08">2021-04-08</time></span><span class="level-item">8 minutes read (About 1264 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Machine-Learning-Week09/">Machine Learning Week09</a></h1><div class="content"><h1 id="Anomaly-Detection-异常检测"><a href="#Anomaly-Detection-异常检测" class="headerlink" title="Anomaly Detection 异常检测"></a>Anomaly Detection 异常检测</h1><h2 id="Density-Estimation"><a href="#Density-Estimation" class="headerlink" title="Density Estimation"></a>Density Estimation</h2><h3 id="Problem-Motivation"><a href="#Problem-Motivation" class="headerlink" title="Problem Motivation"></a>Problem Motivation</h3><p>异常检测主要用于unsupervised learning</p>
<p>Model：$P(x_{test}&lt;\epsilon)\rightarrow anomaly$</p>
<p>​                $P(x_{test}\ge \epsilon)\rightarrow OK$</p>
<p>也被用于检测账号被盗、生产、数据中心的电脑</p>
<h3 id="Gaussian-Distribution"><a href="#Gaussian-Distribution" class="headerlink" title="Gaussian Distribution"></a>Gaussian Distribution</h3><p>=Normal distribution</p>
<p>X ～ N (0, 1)，“distributed as”, 这里N的符号为”script N”</p>
<p>给定dataset，参数估计：via Maximum likelihood estimation 通常是m-1，对大数据集没影响</p>
<script type="math/tex; mode=display">
\mu = \frac{1}{m}\sum_{i=1}^mx^{(i)}\\
\sigma^2=\frac{1}{m}\sum_{i=1}^m(x^{(i)}-\mu)^2</script><h3 id="Algorithm"><a href="#Algorithm" class="headerlink" title="Algorithm"></a>Algorithm</h3><p>基本假设，各特征间相互独立</p>
<script type="math/tex; mode=display">
P(x)=\prod_{j=1}^np(x_j;\mu_j,\sigma_j^2)</script><p><img src="https://cdn.jsdelivr.net/gh/xuJ14/ImageHost@latest/images/image-20210404220930233.png" alt="Anomaly detection algorithm"></p>
<h2 id="Building-an-Anomaly-Detection-System"><a href="#Building-an-Anomaly-Detection-System" class="headerlink" title="Building an Anomaly Detection System"></a>Building an Anomaly Detection System</h2><h3 id="Developing-and-Evaluating-an-Anomaly-Detection-System"><a href="#Developing-and-Evaluating-an-Anomaly-Detection-System" class="headerlink" title="Developing and Evaluating an Anomaly Detection System"></a>Developing and Evaluating an Anomaly Detection System</h3><p>Training set: normal examples (可以有少量异常的混进来)</p>
<p>然后应用于cross calidation set 和 test set</p>
<ul>
<li><p>10000正常，20异常：</p>
<p>​    训练集：6000正常</p>
<p>​    CV：2000正常，10异常</p>
<p>​    Test：2000正常，10异常</p>
</li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/xuJ14/ImageHost@latest/images/image-20210405114004132.png" alt="Algorithm evaluation"></p>
<p>由于normal是0，所以预测0常常有更高的准确率，是skew的偏斜的。因此查准率accuracy不是很好的分析指标。</p>
<ul>
<li>选择ε时，可以试几个不同的，然后选择使得Cross validation集中F1-score最大的，或者效果最好的。</li>
<li>有时还需要决定用什么特征</li>
</ul>
<h3 id="Anomaly-detection-vs-Supervised-learning"><a href="#Anomaly-detection-vs-Supervised-learning" class="headerlink" title="Anomaly detection vs. Supervised learning"></a>Anomaly detection vs. Supervised learning</h3><p>Anomaly detection:</p>
<ul>
<li>y=1非常少(0-20常见), y=0占比更大</li>
<li>有大量不同的异常类型，其他算法难于分辨各种类型</li>
<li>有未知异常类型</li>
</ul>
<p>supervised learning：</p>
<ul>
<li>大量的positive 和negative examples</li>
<li>有足够positive examples，并且未来的positive example和训练集的相似</li>
<li>Spam</li>
</ul>
<h3 id="Choosing-what-features-to-use"><a href="#Choosing-what-features-to-use" class="headerlink" title="Choosing what features to use"></a>Choosing what features to use</h3><ul>
<li>Non-gaussian feature</li>
</ul>
<p>绘制特征的直方图，看是否大致是个bell shaped curve，如果不是，运用一些变换使得其看起来更加gaussian</p>
<p><img src="https://cdn.jsdelivr.net/gh/xuJ14/ImageHost@latest/images/image-20210405203939050.png" alt="take a log transformation"></p>
<ul>
<li><p>Error analysis for anomaly detection</p>
<p>甄别失败时，new feature 可能有帮助，例如组合现有的特征形成新特征</p>
</li>
</ul>
<h2 id="Multivariate-Gaussian-Distribution"><a href="#Multivariate-Gaussian-Distribution" class="headerlink" title="Multivariate Gaussian Distribution"></a>Multivariate Gaussian Distribution</h2><h3 id="Multivariate-Gaussian-Distribution-1"><a href="#Multivariate-Gaussian-Distribution-1" class="headerlink" title="Multivariate Gaussian Distribution"></a>Multivariate Gaussian Distribution</h3><p>不同于之前的是，p(x)不再是各个特征概率的乘积。</p>
<p>Parameters: $\mu \in \R^n$, $\Sigma \in \R^{n\times n}$</p>
<script type="math/tex; mode=display">
p(x;\mu,\Sigma)= \frac{1}{(2\pi)^{\frac{n}{2}}|\Sigma|^2}exp(-\frac{1}{2}(x-\mu)^T\Sigma^{-1}(x-\mu))</script><p>$|\Sigma|$=determinant of Σ </p>
<p><img src="https://cdn.jsdelivr.net/gh/xuJ14/ImageHost@latest/images/image-20210405214331278.png" alt="examples"></p>
<script type="math/tex; mode=display">
\mu = \frac{1}{m}\sum_{i=1}^mx^{(i)}\\
\Sigma = \frac{1}{m}\sum_{i=1}^m(x^{(i)}-\mu)(x^{(i)}-\mu)^T</script><h3 id="Anomaly-Detection-using-the-multivariate-Gaussian-distribution"><a href="#Anomaly-Detection-using-the-multivariate-Gaussian-distribution" class="headerlink" title="Anomaly Detection using the multivariate Gaussian distribution"></a>Anomaly Detection using the multivariate Gaussian distribution</h3><p>首先计算μ和Σ，然后计算p(x)，最后根据ε判断是否异常</p>
<ul>
<li><p>优点：自动捕捉特征间的相关性。m&gt;10n用起来才比较好，必须要m&gt;n，否则协方差矩阵不可逆。</p>
</li>
<li><p>缺点：计算量比较大。如果某个特征是其他的线性组合，那么协方差矩阵也不可逆，要注意避免。</p>
</li>
</ul>
<p>前述的模型：优点在于计算量小，但是要人工创造一些新特征来更好地分辨。m&lt;n的时候也能用。</p>
<p>若出现协方差矩阵不可逆：</p>
<ul>
<li>首先检查m, n大小</li>
<li>检查是否有redundant features，就是特征间是否线性独立</li>
</ul>
<h2 id="Predicting-Movie-Ratings-——Recommendation-System"><a href="#Predicting-Movie-Ratings-——Recommendation-System" class="headerlink" title="Predicting Movie Ratings ——Recommendation System"></a>Predicting Movie Ratings ——Recommendation System</h2><h3 id="Problem-Formulation"><a href="#Problem-Formulation" class="headerlink" title="Problem Formulation"></a>Problem Formulation</h3><p>r(i,j) 表示第i个电影，j用户是否打分；</p>
<p>y(i,j) 表示该用户对该电影的打分值 ；</p>
<h3 id="Content-Based-Recommendations"><a href="#Content-Based-Recommendations" class="headerlink" title="Content Based Recommendations"></a>Content Based Recommendations</h3><p>设电影特征n个</p>
<p>For each user j, learn a parameter $\theta^{(j)}\in\R^{n+1}$. Predict user j as rating movie i with $(\theta^{(j)})^Tx^{(i)}$ stars. （注意 $x_0=1$）。用线性回归</p>
<p>To learn $\theta^{(j)}$：</p>
<script type="math/tex; mode=display">
\min_{\Theta^{(j)}}\frac{1}{2m^{(j)}}\sum_{i:r(i,j)=1}((\theta^{(j)})^Tx^{(i)}-y^{(i,j)})^2+\frac{\lambda}{2m^{(j)}}\sum_{k=1}^{n}(\theta_k^{(j)})^2</script><p>Note: 这里 $m^{(j)}$可以去掉，对结果没有任何影响</p>
<p>优化目标也可以为：</p>
<script type="math/tex; mode=display">
J(\Theta^{(1)},...,\Theta^{(n_u)})=\min_{\Theta^{(1)},...,\Theta^{(n_u)}}\frac{1}{2}\sum_{j=1}^{n_u}\sum_{i:r(i,j)=1}((\theta^{(j)})^Tx^{(i)}-y^{(i,j)})^2+\frac{\lambda}{2}\sum_{j=1}^{n_u}\sum_{k=1}^{n}(\theta_k^{(j)})^2</script><p>Gradient descent update:</p>
<script type="math/tex; mode=display">
\theta_{k}^{(j)}:=\theta_{k}^{(j)}-\alpha \sum_{i: r(i, j)=1}\left(\left(\theta^{(j)}\right)^{T} x^{(i)}-y^{(i, j)}\right) x_{k}^{(i)}\ (\text { for } k=0)</script><script type="math/tex; mode=display">
\theta_{k}^{(j)}:=\theta_{k}^{(j)}-\alpha\left(\sum_{i: r(i, j)=1}\left(\left(\theta^{(j)}\right)^{T} x^{(i)}-y^{(i, j)}\right) x_{k}^{(i)}+\lambda \theta_{k}^{(j)}\right)\ (\text { for } k \neq 0)</script><p>k=0的时候不加正则项</p>
<h2 id="Collaborative-Filtering"><a href="#Collaborative-Filtering" class="headerlink" title="Collaborative Filtering"></a>Collaborative Filtering</h2><h3 id="Collaborative-Filtering-1"><a href="#Collaborative-Filtering-1" class="headerlink" title="Collaborative Filtering"></a>Collaborative Filtering</h3><ul>
<li>feature learning</li>
<li>Given $\Theta^{(1)},…,\Theta^{(n_u)}$，to learn $x^{(1)},…,x^{(n_m)}$;</li>
<li>算法类似7、8式</li>
<li>$用户的\Theta\rightarrow 电影特征x\rightarrow \Theta\rightarrow x\rightarrow…$</li>
<li><p>每个用户都在帮助这个推荐系统更好地分类电影，从而更好地预测评分</p>
</li>
<li><p>算法：同时实现：</p>
<ol>
<li><p>Given $x^{(1)},…,x^{(n_m)}$，estimate $\theta^{(1)},…,\theta^{(n_u)}$：</p>
<script type="math/tex; mode=display">
\min_{\Theta^{(j)}}\frac{1}{2m^{(j)}}\sum_{i:r(i,j)=1}((\theta^{(j)})^Tx^{(i)}-y^{(i,j)})^2+\frac{\lambda}{2m^{(j)}}\sum_{k=1}^{n}(\theta_k^{(j)})^2</script></li>
<li><p>Given $\theta^{(1)},…,\theta^{(n_u)}$，estimate $x^{(1)},…,x^{(n_m)}$：</p>
<script type="math/tex; mode=display">
\min _{x^{(1)}, \ldots, x^{\left(n_{m}\right)}} \frac{1}{2} \sum_{i=1}^{n_{m}} \sum_{j: r(i, j)=1}\left(\left(\theta^{(j)}\right)^{T} x^{(i)}-y^{(i, j)}\right)^{2}+\frac{\lambda}{2} \sum_{i=1}^{n_{m}} \sum_{k=1}^{n}\left(x_{k}^{(i)}\right)^{2}</script></li>
</ol>
<p>即：</p>
<p>Minimizing $x^{(1)},…,x^{(n_m)}$ and $\theta^{(1)},…,\theta^{(n_u)}$ simultaneously：</p>
<script type="math/tex; mode=display">
\min_{x^{(1)},...,x^{(n_m)}\\\theta^{(1)},...,\theta^{(n_u)}}J\left(x^{(1)}, \ldots, x^{\left(n_{m}\right)}, \theta^{(1)}, \ldots, \theta^{\left(n_{u}\right)}\right)</script><script type="math/tex; mode=display">
J\left(x^{(1)}, \ldots, x^{\left(n_{m}\right)}, \theta^{(1)}, \ldots, \theta^{\left(n_{u}\right)}\right)=\frac{1}{2} \sum_{(i, j): r(i, j)=1}\left(\left(\theta^{(j)}\right)^{T} x^{(i)}-y^{(i, j)}\right)^{2}+\frac{\lambda}{2} \sum_{i=1}^{n_{m}} \sum_{k=1}^{n}\left(x_{k}^{(i)}\right)^{2}+\frac{\lambda}{2} \sum_{j=1}^{n_{u}} \sum_{k=1}^{n}\left(\theta_{k}^{(j)}\right)^{2}</script><blockquote>
<p>该算法下，无需设定 $x_0=1$, 也没有$\theta_0$，因为算法会自行选择参数。该算法下：$\theta\in\R^n$，$x\in\R^n$，n是特征数</p>
</blockquote>
</li>
<li><p>算法实现：</p>
<ol>
<li>Initialize $x^{(1)},…,x^{(n_m)}$， $\theta^{(1)},…,\theta^{(n_u)}$ to small random values</li>
<li>Minimize J using gradient descent (or an advanced optimization algorithm)</li>
<li>For a user with parameters $\theta$ and a movie with (learned) features x, predict a star rating of $\theta^Tx$</li>
</ol>
</li>
</ul>
<h2 id="Low-Rank-Matrix-Factorization"><a href="#Low-Rank-Matrix-Factorization" class="headerlink" title="Low Rank Matrix Factorization"></a>Low Rank Matrix Factorization</h2><h3 id="Vectorization"><a href="#Vectorization" class="headerlink" title="Vectorization"></a>Vectorization</h3><ul>
<li><p>Given matrices X (each row containing features of a particular movie) and Θ (each row containing the weights for those features for a given user), then the full matrix Y of all predicted ratings of all movies by all users is given simply by: $Y = X\Theta^T$.</p>
</li>
<li><p>Predicting how similar two movies i and j are can be done using the distance between their respective feature vectors x. Specifically, we are looking for a small value of $||x^{(i)} - x^{(j)}||$.</p>
</li>
</ul>
<h3 id="Mean-Normalization"><a href="#Mean-Normalization" class="headerlink" title="Mean Normalization"></a>Mean Normalization</h3><p>If the ranking system for movies is used from the previous lectures, then new users (who have watched no movies), will be assigned new movies incorrectly. Specifically, they will be assigned θ with all components equal to zero due to the minimization of the regularization term. That is, we assume that the new user will rank all movies 0, which does not seem intuitively correct. 新用户会被预测为0</p>
<p>We rectify this problem by normalizing the data relative to the mean. First, we use a matrix Y to store the data from previous ratings, where the ith row of Y is the ratings for the ith movie and the jth column corresponds to the ratings for the jth user.</p>
<p>We can now define a vector</p>
<script type="math/tex; mode=display">
\mu  = [\mu_1, \mu_2, \dots , \mu_{n_m}]</script><p>such that</p>
<script type="math/tex; mode=display">
\mu_i = \frac{\sum_{j:r(i,j)=1}{Y_{i,j}}}{\sum_{j}{r(i,j)}}</script><p>Which is effectively the mean of the previous ratings for the ith movie (where only movies that have been watched by users are counted). We now can normalize the data by subtracting u, the mean rating, from the actual ratings for each user (column in matrix Y):</p>
<p>As an example, consider the following matrix Y and mean ratings μ:</p>
<script type="math/tex; mode=display">
Y=\left[\begin{array}{cccc}
5 & 5 & 0 & 0 \\
4 & ? & ? & 0 \\
0 & 0 & 5 & 4 \\
0 & 0 & 5 & 0
\end{array}\right], \quad \mu=\left[\begin{array}{c}
2.5 \\
2 \\
2.25 \\
1.25
\end{array}\right]</script><p>The resulting Y′ vector is:</p>
<script type="math/tex; mode=display">
Y^{\prime}=\left[\begin{array}{cccc}
2.5 & 2.5 & -2.5 & -2.5 \\
2 & ? & ? & -2 \\
-2 .25 & -2.25 & 3.75 & 1.25 \\
-1.25 & -1.25 & 3.75 & -1.25
\end{array}\right]</script><p>Now we must slightly modify the linear regression prediction to include the mean normalization term:</p>
<script type="math/tex; mode=display">
(\theta^{(j)})^T x^{(i)} + \mu_i</script><p>Now, for a new user, the initial predicted values will be equal to the μ term instead of simply being initialized to zero, which is more accurate.</p>
<blockquote>
<p>Note: 一般的均值归一化要除以range，即max-min，但是这里不需要，因为都有统一的scale</p>
</blockquote>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-03-30T12:51:04.000Z" title="2021/3/30 上午8:51:04">2021-03-30</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-03-30T13:42:07.285Z" title="2021/3/30 上午9:42:07">2021-03-30</time></span><span class="level-item">a few seconds read (About 0 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/My-Application-Review/">My Application Review</a></h1><div class="content">This article has been encrypted. Please input the password.</div><a class="article-more button is-small is-size-7" href="/My-Application-Review/#more">Read more</a></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-03-30T10:29:49.000Z" title="2021/3/30 上午6:29:49">2021-03-30</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-03-30T12:24:05.572Z" title="2021/3/30 上午8:24:05">2021-03-30</time></span><span class="level-item">11 minutes read (About 1589 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Machine-Learning-Week06/">Machine Learning Week06</a></h1><div class="content">Evaluate the learning algorithm</div><a class="article-more button is-small is-size-7" href="/Machine-Learning-Week06/#more">Read more</a></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-03-27T03:33:26.000Z" title="2021/3/26 下午11:33:26">2021-03-26</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-03-30T12:58:13.193Z" title="2021/3/30 上午8:58:13">2021-03-30</time></span><span class="level-item">a minute read (About 195 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Issues-of-Icarus/">Issues of Icarus</a></h1><div class="content">Issues of Icarus</div><a class="article-more button is-small is-size-7" href="/Issues-of-Icarus/#more">Read more</a></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-03-25T15:15:00.000Z" title="2021/3/25 上午11:15:00">2021-03-25</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-04-03T10:13:08.883Z" title="2021/4/3 上午6:13:08">2021-04-03</time></span><span class="level-item">10 minutes read (About 1477 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Machine-Learning-Week08/">Machine Learning Week08</a></h1><div class="content">Unsupervised Learning 待完成</div><a class="article-more button is-small is-size-7" href="/Machine-Learning-Week08/#more">Read more</a></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-03-25T15:14:54.000Z" title="2021/3/25 上午11:14:54">2021-03-25</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-04-03T06:41:29.908Z" title="2021/4/3 上午2:41:29">2021-04-03</time></span><span class="level-item">8 minutes read (About 1269 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Machine-Learning-Week07/">Machine Learning Week07</a></h1><div class="content">Support Vector Machines</div><a class="article-more button is-small is-size-7" href="/Machine-Learning-Week07/#more">Read more</a></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-03-25T15:14:43.000Z" title="2021/3/25 上午11:14:43">2021-03-25</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-03-27T17:02:59.228Z" title="2021/3/27 下午1:02:59">2021-03-27</time></span><span class="level-item">8 minutes read (About 1262 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Machine-Learning-Week05/">Machine Learning Week05</a></h1><div class="content">Neural Networks</div><a class="article-more button is-small is-size-7" href="/Machine-Learning-Week05/#more">Read more</a></article></div><nav class="pagination" role="navigation" aria-label="pagination"><div class="pagination-previous is-invisible is-hidden-mobile"><a href="/page/0/">Previous</a></div><div class="pagination-next"><a href="/page/2/">Next</a></div><ul class="pagination-list is-hidden-mobile"><li><a class="pagination-link is-current" href="/">1</a></li><li><a class="pagination-link" href="/page/2/">2</a></li></ul></nav></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="/img/icon.jpg" alt="Jun XU"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Jun XU</p><p class="is-size-6 is-block">MFE candidate</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Shanghai</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">16</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">0</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">5</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/xuJ14" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/xuJ14"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2021/04/"><span class="level-start"><span class="level-item">April 2021</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/03/"><span class="level-start"><span class="level-item">March 2021</span></span><span class="level-end"><span class="level-item tag">12</span></span></a></li></ul></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">Subscribe for updates</h3><form action="https://feedburner.google.com/fb/a/mailverify" method="post" target="popupwindow" onsubmit="window.open(&#039;https://feedburner.google.com/fb/a/mailverify?uri=&#039;,&#039;popupwindow&#039;,&#039;scrollbars=yes,width=550,height=520&#039;);return true"><input type="hidden" value="" name="uri"><input type="hidden" name="loc" value="en_US"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="Subscribe"></div></div></form></div></div></div><div class="column-right-shadow is-hidden-widescreen is-sticky"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3 is-sticky"><!--!--><!--!--><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-04-18T19:25:01.000Z">2021-04-18</time></p><p class="title"><a href="/Machine-Learning-Week10/">Machine Learning Week10</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-04-04T14:40:50.000Z">2021-04-04</time></p><p class="title"><a href="/Reading-List/"> </a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-04-04T14:24:26.000Z">2021-04-04</time></p><p class="title"><a href="/How-to-Read-Papers/">How to Read Papers</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-04-04T14:16:35.000Z">2021-04-04</time></p><p class="title"><a href="/Machine-Learning-Week09/">Machine Learning Week09</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-03-30T12:51:04.000Z">2021-03-30</time></p><p class="title"><a href="/My-Application-Review/">My Application Review</a></p></div></article></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/Essay/"><span class="tag">Essay</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Issues/"><span class="tag">Issues</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Learning-Tips/"><span class="tag">Learning Tips</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Machine-Learning/"><span class="tag">Machine Learning</span><span class="tag">10</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Private/"><span class="tag">Private</span><span class="tag">1</span></a></div></div></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="Jun&#039;s Blog" height="28"></a><p class="is-size-7"><span>&copy; 2022 Jun XU</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>