{"pages":[],"posts":[{"title":"How to Read Papers","text":"How to Read Papers?Resources Arxiv Blog Posts Text Books Prepare 列出待读论文，每一篇列一行，表示从0-100的阅读进度 如果有论文不是想要的，就删掉 如果有新的论文就加进来 Methods 第一遍：只看标题，摘要，图表 第二遍：前言，结语，图表 第三遍：论文主体","link":"/How-to-Read-Papers/"},{"title":"Issues of Icarus","text":"Upload 每次上传都需要密码_config.yml中将仓库地址改为：git@github.com: yourname/yourname.github.io.git WidgetsPostsContent Image not showing up Image should be under source/gallery/. Use Hexo’s tag: 1{% img /gallery/image.jpg \"image title\" %\\} Excerpt / Read more Put a &lt;! — more —&gt;tag in the post. Or in the front-matter, “excerpt: the content of the excerpt” Image host via github Formula 无法正确渲染 完美解决方案 上述方案无法解决类似*$这样的问题，如何解决？？ hexo公式换行的问题？？ 公式内的“\\#”无法解析，或其他公式渲染问题，报”Template render error”错误尽量不要用#符号","link":"/Issues-of-Icarus/"},{"title":"Machine Learning Week02","text":"Multiple FeatureMultivariate Linear Regression $h_{\\theta}(x)=\\theta^{T}X$ $h_θ(x)=\\begin{bmatrix}θ_0&amp;θ_1&amp;…&amp;θ_n\\end{bmatrix}\\begin{bmatrix}x_0\\\\x_1\\\\⋮\\\\x_n\\end{bmatrix}=θ^Tx$ Gradient Descent for Multiple Variables Cost function: J(\\theta_0,\\theta_1...\\theta_n)=\\frac {1}{2m}\\sum \\limits_{i=1}^m(h_\\theta(x^{(i)})-y^{(i)})^2 \\theta_j:=\\theta_j-\\alpha\\frac {\\partial} {\\partial \\theta_j}J(\\theta)=\\theta_j-\\alpha\\frac {1}{m}\\sum \\limits_{i=1}^m(h_\\theta(x^{(i)})-y^{(i)})x_j^{(i)}\\quad(for\\ j=0...n) Feature Scaling Make sure features are on a similar scale 避免梯度下降一个维度值过大导致下降速率很慢 Get every feature into approximately a $-1\\le x_i\\le 1$ range 大约在这个范围附近就行，例如: $-2\\le x_i\\le 2$也可以 方法一：都除以最大值$x_{max}$ 均值归一化 Mean normalization： \\frac{x_i-\\mu_i}{s_{i}} 使得均值为0 $\\mu$是训练集x某特征的均值，s可以是标准差，一般$s=max-min$即可 特征缩放不用太精确，只是为了让梯度下降更快而已 确定α 如果α过大，则可能出现 J 值增大或者不收敛 让α尽量小，使得每次迭代 J 值都在减小 自动收敛测试：可以设定一个值比如0.001，如果每一步J变化小于这个值即可认为收敛，但是选择合适的值很困难 所以可以采用：代价函数 J 随迭代步数变化曲线，可以帮助判断梯度下降算法是否收敛 多项式回归 Polynomial Regression 拟合复杂函数 将x进行平方、开根等处理。例如：$x_3=x_1^3$ 注意新特征要进行均值归一化使得各个特征之间差距不至于过大 Normal equation 正规方程 solve for θ analytically，θ的解析解法 J(\\theta_0,\\theta_1...\\theta_n)=\\frac {1}{2m}\\sum \\limits_{i=1}^m(h_\\theta(x^{(i)})-y^{(i)})^2 ，令$\\frac {\\partial} {\\partial \\theta_j}J(\\theta)=0$(偏微分) $X=\\begin{bmatrix}x_0&amp;x_1&amp;…&amp;x_n\\end{bmatrix}$，x代表特征的列向量集合 则可以推出：$\\theta=(X^TX)^{-1}X^Ty$，即正规方程 matlab：pinv(X‘*X)*X’*y 用正规方程就不用变量归一化 优点：不用选择α；不用迭代 缺点：n较大时，算逆矩阵会比较慢，n&gt;10000，复杂度大约在$O(n^3)$ 正规方程的不可逆性 Normal Equation Non-invertibility pinv可以求伪逆，inv求逆 如果$X^TX$是不可逆的： 特征之间是相关的 特征多于样本数 解决方法：删除多余特征或正则化","link":"/Machine-Learning-Week02/"},{"title":"Machine Learning Week01","text":"Week 1 Supervised Learning 监督学习 分类问题 classification problem discrete output（0，1） features 特征无限多的时候可以用SVM支持向量机 回归问题 regression problem continuous output Unsupervised Learning 无监督学习 clustering algorithm 聚类算法 dataset（no label） find structure;根据数据内部关系分类 E.g. 网站分类；基因分类；social network analysis；market segmentation；Astronomical data analysis Cocktail party problem：混杂的声音中分离出两种声音 1[W,s,v] = svd((repmat(sum(x.*x,1),size(x,1),1).*x)*x') *SVD: singular value decomposition 奇异值分解，求解线性方程 octave做原型，然后迁移到C或JAVA Model and Cost Function 模型和成本函数 线性回归算法 linear regression training set 训练集 m - 训练样本数 x - 输入变量 y - 输出变量 $(x^{i},y^{i})$ - i training example $\\theta$ - Parameters h - hypothesis，x映射到y的函数 ：$h_{\\theta}(x)=\\theta_0+\\theta_1x$；缩写即$h(x)$ 不一定都是线性方程 Cost Function 成本函数 度量函数拟合的程度 平方误差成本函数：适用于线性回归 Hypothesis: \\min \\limits_{\\theta_0\\theta_1}\\frac {1}{2m}\\sum \\limits_{i=1}^m(h_\\theta(x^{(i)})-y^{(i)})^2 Cost function: J(\\theta_0,\\theta_1)=\\frac {1}{2m}\\sum \\limits_{i=1}^m(h_\\theta(x^{(i)})-y^{(i)})^2 ——- (Squared Error Function) contour plot: 轮廓图；等高线图 Parameter Learning Gradient descent 梯度下降算法 不断改变$\\theta$使得J函数变小，得到局部最优点local optimum，convergence收敛 \\theta_j:=\\theta_j-\\alpha\\frac {\\partial} {\\partial \\theta_j}J(\\theta_0,\\theta_j)\\quad(for\\ j=0\\ and\\ j=1)$\\alpha$是学习速率 learning rate 注意编程中的赋值后会覆盖，所以要桥接一下 partial derivatives 偏导数；derivatives 导数 不需要调整α因为导数值越来越小 Batch Gradient Descent 批量梯度下降：每step都用到全部的训练样本 高等线性代数：normal equations method正规方程，大数据时梯度下降更好用 Matrices and Vectors Matrix: rows*columns $\\mathbb{R} ^{2\\times3}$ , $A_{ij}$, Vector: n*1 matrix $\\mathbb{R}^4$ $A\\times B\\ne B\\times A$ Associative交换律 Identity Matrix： $I$, $n\\times n$ $\\begin{bmatrix}1&amp;\\cdots&amp;0\\\\\\vdots&amp;\\ddots&amp;\\vdots\\\\0&amp;\\cdots&amp;1\\end{bmatrix}$ $A\\cdot I=I\\cdot A$ I = eye(2) Inverse 矩阵的逆：$A(A^{-1})=A^{-1}A=I$ pinv（A） $A_{m\\times m}$ 0矩阵=奇异矩阵，没有逆矩阵的矩阵是奇异矩阵 高斯消元法求逆： “某行乘以一个数后加到另一行”、“某两行互换位置”、“某行乘以某一个数”，这三种以行做运算的方法 行变换或列变换都可以 增广矩阵$B=[A|I]=\\begin{vmatrix} A_{11} &amp; A_{12} &amp; A_{13}&amp;1&amp;0&amp;0 \\\\ A_{21} &amp; A_{22}&amp;A_{23}&amp;0&amp;1&amp;0\\\\A_{31} &amp; A_{32} &amp; A_{33}&amp;0&amp;0&amp;1 \\end{vmatrix} \\Rightarrow \\begin{vmatrix} 1&amp;0&amp;0&amp;A_{11}^{‘} &amp; A_{12}^{‘} &amp; A_{13}^{‘} \\\\0&amp;1&amp;0&amp;A_{21}^{‘} &amp; A_{22}^{‘} &amp; A_{23}^{‘}\\\\0&amp;0&amp;1&amp;A_{31}^{‘} &amp; A_{32}^{‘} &amp; A_{33}^{‘} \\end{vmatrix}$ 待定系数法 伴随矩阵法$A^* $，$A^{-1}=\\frac {A^*}{|A|}$ 将矩阵A元素$a_{ij}$所在的第i行j列元素划去后剩余元素按照原来顺序组成n-1阶矩阵所确定的行列式成为元素$a_{ij}$的余子式，记为$M_{ij}$，称$A_{ij}=(-1)^{i+j}M_{ij}$为元素$a_{ij}$的代数余子式 $A^*$的第i行j列元素为上面的$A_{ij}$ LU分解法A=LU，$A^{-1}=U^{-1}L^{-1}$ SVD分解法 QR分解法 Transpose 矩阵的转置：$A^T$","link":"/Machine-Learning-Week01/"},{"title":"Machine Learning Week03","text":"Machine LearningWeek 03 Classification and Representation | Overfitting1. Classification and Representation 分类和表征 Logistic Regression算法应用于Classification binary classification problem 二元分类问题 函数值是离散的discrete Hypothesis Representation 假设陈述 因为需要$y∈\\{0,1\\}$，所以要使得$0\\le h_\\theta(x)\\le1$，令h_\\theta(x)=g(\\theta^Tx),\\ z=\\theta^Tx,\\ g(x)=\\frac {1}{1+e^{-z}} $h_\\theta(x)$表示输出为1的概率: h_\\theta(x)=P(y=1|x;\\theta)=1-P(y=0|x;\\theta) Decision Boundary 决策边界：分类的边界 h_\\theta(x)=g(\\theta_0+\\theta_1x_1+\\theta_2x_2) 非线性(non-linear)决策边界 多项式是决策边界的属性，不是训练集的属性，训练集决定参数θ的值 2. Logistic Regression Model 逻辑回归模型 Cost Function convex 凸函数，可以收敛到全局最小 不能使用linear regression的Cost function，因为这会使得logistic function的成本函数变成波浪形，形成许多局部最优，就无法形成凸函数 因此替换成本函数为： J(\\theta)=\\frac {1}{m}\\sum \\limits_{i=1}^mCost(h_\\theta(x^{(i)}),y^{(i)}) \\\\ Cost(h_\\theta(x),y)= \\begin{cases}-log(h_\\theta(x)) & \\quad if\\ y=1 \\\\ -log(1-h_\\theta(x)) & \\quad if\\ y=0 \\end{cases} The cost function in this way guarantees that J(θ) is convex for logistic regression. 这里的Cost function等价于： Cost(h_\\theta(x),y)=-ylog(h_\\theta(x))-(1-y)log(1-h_\\theta(x)) 带入到代价函数 J(θ) 中 使用==最大似然估计法==可以得出这个代价函数，最大似然估计可以有效地为不同模型找到参数数据。 凸性是这个函数优秀地属性之一 接下来：为了拟合θ，就要最小化 J(θ) Gradient Descent 梯度下降法 \\theta_j:=\\theta_j-\\alpha\\frac {\\partial} {\\partial \\theta_j}J(\\theta)=\\theta_j-\\alpha\\frac {1}{m}\\sum \\limits_{i=1}^m(h_\\theta(x^{(i)})-y^{(i)})x_j^{(i)}\\quad(for\\ j=0...n) 选择学习速率：绘制 J(θ) 关于迭代次数的函数，使得每一次迭代函数值都在下降 可以使用向量化实现算法 \\begin{array}{lc} h=g(\\theta^TX)\\\\ J(\\theta)=\\frac{1}{m}\\cdot(-y^Tlog(h)-(1-y)^Tlog(1-h))\\\\ \\text{注：这里X是$（n+1）\\times1$维列向量} \\end{array}最终得到： \\theta:=\\theta-\\frac{\\alpha}{m}X(g(\\theta^TX)-\\vec{y}) 特征值缩放也同样适用该模型 关于代价函数的最大似然估计法相关数学推导参见这里 ==统计学是机器学习的数学基础== Optimization algorithm 优化算法 例如： Conjugate gradient 共轭梯度法 BFGS变尺度法 L-BFGS限制变尺度法 优点：无需手动选择α（线性搜索法每一步都在改变α）；比梯度下降法收敛更快 缺点：算法更复杂、难理解 octave中的优化算法表达： 1234function [jVal, gradient] = costFunction(theta) jVal = [...code to compute J(theta)...]; gradient = [...code to compute derivative of J(theta)...];end 123options = optimset('GradObj', 'on', 'MaxIter', 100);initialTheta = zeros(2,1); [optTheta, functionVal, exitFlag] = fminunc(@costFunction, initialTheta, options); 3. Multiclass Classification 多类别分类问题 one-vs-all 一对多分类算法 划分为多个二分类问题，求多个h(x)。应用于预测集时，将x分类到h最大的那个集里。 $h^{(i)}_\\theta(x)=P(y=i|x;\\theta),\\quad prediction=\\max\\limits_{i}(h^{(i)}_\\theta(x))$ 4. Overfitting 过拟合 underfitting —— 高bias偏差（Bias反映的是模型在样本上的输出与真实值之间的误差，即模型本身的精准度，即算法本身的拟合能力） Overfitting —— 高variance方差（variance反映的是模型每一次输出结果与模型输出期望之间的误差，即模型的稳定性。反应预测的波动情况。） 关于方差与偏差的意义参见这里 解决过拟合： 减少特征的数量 手动选择保留的特征 模型选择算法model selection algorithm，可以自动决定要保留的变量和要剔除的变量 缺点：剔除了一部分信息 regularization 正则化 保留所有变量，减少变量θ的magnitude 在有很多变量时很有用 正则化 在代价函数加一个正则化项，使得参数θ尽可能小，排除bias偏差项 \\min\\limits_\\theta\\frac{1}{2m}\\sum \\limits_{i=1}^m(h_\\theta(x^{(i)})-y^{(i)})x_j^{(i)}+\\lambda\\sum\\limits_{j=1}^n\\theta_j^2 λ是正则化参数regularization parameter 应用于梯度下降法：（注：$\\theta_0$一定不要正则化！） \\theta_j:=\\theta_j-\\alpha\\frac {\\partial} {\\partial \\theta_j}J(\\theta)=\\theta_j-\\alpha[\\frac {1}{m}\\sum \\limits_{i=1}^m(h_\\theta(x^{(i)})-y^{(i)})x_j^{(i)}+\\frac{\\lambda}{m}\\theta_j]\\quad(for\\ j=1...n) 应用于正规方程normal equation： \\theta=(X^TX+\\lambda\\cdot L)^{-1}X^Ty\\\\ where \\quad L=\\begin{bmatrix}0\\\\\\ &1\\\\\\ &\\ &1\\\\\\ &\\ &\\ &\\ddots\\\\\\ &\\ &\\ &\\ &1\\\\\\end{bmatrix} Non-invertibility 不可逆性suppose $m\\le n$, 特征多于例子时，$\\theta=(X^TX)^{-1}X^Ty$ 中，$X^TX$是不可逆的（或奇异的），即为退化矩阵（degenerate）但是加入λL 后，解决了上述问题，公式（9）括号内的矩阵是可逆的（前提是λ&gt;0）","link":"/Machine-Learning-Week03/"},{"title":"Machine Learning Week04","text":"Neural Networks： Representation1. Non-linear Hypotheses特征多，有高次项 2. Neural Networks Model representation bias unit偏置项（=1） sigmoid activation function S型激励函数 input layer —— hidden layer —— output layer a_i^{(j)}= \"activation\"\\ of\\ unit\\ i\\ in\\ layer\\ j$\\Theta^{(j)}=$ matrix of weights controlling function mapping from layer j to layer j+1 ，即参数矩阵（波矩阵、权重矩阵） 如果一个网络在 j 层有$s_j$个单元，j+1层有$s_{j+1}$个单元，那么$\\Theta^{(j)}$的矩阵维度是$s_{j+1}\\times(s_j+1)$，因为要加上bias unit \\begin{array}{r} a_{1}^{(2)}=g\\left(\\Theta_{10}^{(1)} x_{0}+\\Theta_{11}^{(1)} x_{1}+\\Theta_{12}^{(1)} x_{2}+\\Theta_{13}^{(1)} x_{3}\\right)=g(z_1^{(2)}) \\\\ a_{2}^{(2)}=g\\left(\\Theta_{20}^{(1)} x_{0}+\\Theta_{21}^{(1)} x_{1}+\\Theta_{22}^{(1)} x_{2}+\\Theta_{23}^{(1)} x_{3}\\right)=g(z_2^{(2)}) \\\\ a_{3}^{(2)}=g\\left(\\Theta_{30}^{(1)} x_{0}+\\Theta_{31}^{(1)} x_{1}+\\Theta_{32}^{(1)} x_{2}+\\Theta_{33}^{(1)} x_{3}\\right) =g(z_3^{(2)}) \\\\ h_{\\Theta}(x)=a_{1}^{(3)}=g\\left(\\Theta_{10}^{(2)} a_{0}^{(2)}+\\Theta_{11}^{(2)} a_{1}^{(2)}+\\Theta_{12}^{(2)} a_{2}^{(2)}+\\Theta_{13}^{(2)} a_{3}^{(2)}\\right) \\end{array} 即前向传播（forward propagation） 3. Applications 与运算（-30，20，20） 或运算（-10，20，20） 非运算（10，-20） XNOR运算，同或运算（相同为1，否则为0）：两层神经网络 Multiclass Classification，如果4个分类器结果则例如[0,0,1,0] ​","link":"/Machine-Learning-Week04/"},{"title":"Machine Learning Week05","text":"Neural Networks LearningCost Function and Propagation Cost Function L 神经网络的层数 $s_l$第l层的神经元个数，不包括bias unit K输出层的神经元个数（即种类） binary classification二元分类 Logistic regression的代价函数： J(\\theta)=-\\frac {1}{m}\\sum \\limits_{i=1}^m\\bigg [y^{(i)}log(h_\\theta(x^{(i)}))-(1-y^{(i)})log(1-h_\\theta(x^{(i)}))\\bigg ]+\\frac{\\lambda}{2m}\\sum \\limits_{j=1}^n\\theta_j^2 神经网络的代价函数： J(\\Theta)=-\\frac{1}{m} \\sum_{i=1}^{m} \\sum_{k=1}^{K}\\left[y_{k}^{(i)} \\log \\left((h_{\\Theta}(x^{(i)}))_{k}\\right)+\\left(1-y_{k}^{(i)}\\right) \\log \\left(1-(h_{\\Theta}(x^{(i)}))_{k}\\right)\\right]+\\frac{\\lambda}{2 m} \\sum_{l=1}^{L-1} \\sum_{i=1}^{s_l} \\sum_{j=1}^{s_{l+1}}(\\theta_{j,i}^{(l)})^2 两个求和符号部分只是将输出层中每个单元的逻辑回归代价函数相加 三个求和符号部分只是将整个网络中所有单个θ的平方相加，其中i并不指代训练实例i 反向传播算法Backpropagation Algorithm 梯度下降计算 min J（θ）就需要计算：J（θ）；J（θ）关于各个θ的偏导 计算过程：先forward propagation；再反向 $\\delta_j^{l}=”error”\\ of\\ node\\ j\\ in\\ layer\\ l$用于改变activation激励值, Formally, $\\delta_j^{(l)}=\\frac \\partial {\\partial z_{j}^{(l)}} cost(j)$, 其中$cost(i)=y^{(i)}log(h_\\Theta(x^{(i)}))-(1-y^{(i)})log(1-h_\\Theta(x^{(i)}))$, 求导后易得$\\delta_j^{(l)}=y_j^{(l)}-a_j^{(l)}$(为什么符号是相反的？答：这里cost错误，和前文代价函数符号相反，应该要变号) 计算过程： 令$\\Delta_{i,j}^{l}:=0$ For training example t =1 to m: Set $a^{(1)} := x^{(t)}$ Perform forward propagation to compute $a^{(l)}\\ for\\ l=2,3,…,L$ (此处失效图片链接)img (https://d3c33hcgiwev3.cloudfront.net/imageAssetProxy.v1/bYLgwteoEeaX9Qr89uJd1A_73f280ff78695f84ae512f19acfa29a3_Screenshot-2017-01-10-18.16.50.png?expiry=1606176000000&amp;hmac=9aVGT1io0l-sybFSrc1stejo_L0d7hzlNXbQIt47h2Y) Using $y^{(t)}$, compute$ \\delta^{(L)} = a^{(L)} - y^{(t)}$ Where L is our total number of layers and a^{(L)}a(L) is the vector of outputs of the activation units for the last layer. So our “error values” for the last layer are simply the differences of our actual results in the last layer and the correct outputs in y. To get the delta values of the layers before the last layer, we can use an equation that steps us back from right to left: Compute$ \\delta^{(L-1)}, \\delta^{(L-2)},\\dots,\\delta^{(2)}$using\\delta^{(l)} = ((\\Theta^{(l)})^T \\delta^{(l+1)})\\ .*\\ a^{(l)}\\ .*\\ (1 - a^{(l)}) The delta values of layer l are calculated by multiplying the delta values in the next layer with the theta matrix of layer l. We then element-wise multiply that with a function called g’, or g-prime, which is the derivative of the activation function g evaluated with the input values given by $z^{(l)}$. The g-prime derivative terms can also be written out as: $g′(z^{(l)})=a^{(l)} .∗ (1−a^{(l)})$ $Δ_{i,j}^{(l)}:=Δ_{i,j}^{(l)}+a_j^{(l)}δ_i^{(l+1)}$, or with vectorization, $Δ^{(l)}:=Δ^{(l)}+δ^{(l+1)}(a^{(l)})^T$ Hence we update our new $\\Delta$ matrix. $D_{i, j}^{(l)}:=\\frac{1}{m}\\left(\\Delta_{i, j}^{(l)}+\\lambda \\Theta_{i, j}^{(l)}\\right), \\text { if } j \\neq 0$ $D_{i, j}^{(l)}:=\\frac{1}{m}\\Delta_{i, j}^{(l)}, \\text { if } j = 0$ The capital-delta matrix D is used as an “accumulator” to add up our values as we go along and eventually compute our partial derivative. Thus we get$ \\frac \\partial {\\partial \\Theta_{ij}^{(l)}} J(\\Theta)= D_{ij}^{(l)}$ 上述计算过程的中文推导 Backpropagation in practice 系数展开到向量： M(a,b)，既取a，也取b，从1开始 优化算法（如：fminunc）默认将参数整合到一个向量中 - 1234567%代码过程thetaVector = [ Theta1(:); Theta2(:); Theta3(:); ]deltaVector = [ D1(:); D2(:); D3(:) ]Theta1 = reshape(thetaVector(1:110),10,11)Theta2 = reshape(thetaVector(111:220),10,11)Theta3 = reshape(thetaVector(221:231),1,11) 过程：(此处失效图片链接)img(https://d3c33hcgiwev3.cloudfront.net/imageAssetProxy.v1/kdK7ubT2EeajLxLfjQiSjg_d35545b8d6b6940e8577b5a8d75c8657_Screenshot-2016-11-27-15.09.24.png?expiry=1606348800000&amp;hmac=bH794vb16zxSOiqZRj2Pe0PyuaYNbZ8tDQZlnGSoM18) 梯度检验gradient checking $\\frac{d}{d\\Theta}J(\\Theta)\\approx \\frac{J(\\Theta+\\epsilon)+J(\\Theta-\\epsilon)}{2\\epsilon}$，ε = $10^{-4}$ \\dfrac{\\partial}{\\partial\\Theta_j}J(\\Theta) \\approx \\dfrac{J(\\Theta_1, \\dots, \\Theta_j + \\epsilon, \\dots, \\Theta_n) - J(\\Theta_1, \\dots, \\Theta_j - \\epsilon, \\dots, \\Theta_n)}{2\\epsilon} 12345678epsilon = 1e-4;for i = 1:n, thetaPlus = theta; thetaPlus(i) += epsilon; thetaMinus = theta; thetaMinus(i) -= epsilon; gradApprox(i) = (J(thetaPlus) - J(thetaMinus))/(2*epsilon)end; Check: gradApprox ≈ deltaVector，只需要验证一次即可，否则这种方法会非常慢 Random Initialization随机初始化 Symmetry breaking，因为如果设为一样的会使得梯度下降后参数也一样 将每一个$\\Theta_{ij}^{(l)}$设为在[-ε，ε]之间的随机数，但要同时设置，以防出现相同，例： 1Theta1 = rand(10,11)*2*init_epsilon-init_epsilon; (Note: the epsilon used above is unrelated to the epsilon from Gradient Checking) 总体回顾 一般默认隐藏层每层神经元数量一致 构建一个模型的过程： 初始化模型 Number of input units = dimension of features x^{(i)}x(i) Number of output units = number of classes Number of hidden units per layer = usually more the better (must balance with cost of computation as it increases with more hidden units) Defaults: 1 hidden layer. If you have more than 1 hidden layer, then it is recommended that you have the same number of units in every hidden layer. Training a Neural Network Randomly initialize the weights Implement forward propagation to get $h_\\Theta(x^{(i)})$ for any $x^{(i)}$ Implement the cost function Implement backpropagation to compute partial derivatives Use gradient checking to confirm that your backpropagation works. Then disable gradient checking. Use gradient descent or a built-in optimization function to minimize the cost function with the weights in theta. 对每一个训练样例循环上述步骤（有可能得到局部最优，因为J（θ）是非凸函数）","link":"/Machine-Learning-Week05/"},{"title":"Machine Learning Week06","text":"Deciding What to Try NextEvaluating a Learning Algorithm 误差大的改进方法： 更多数据 更少特征集避免过拟合 更多特征 增加多项式特征 减少或增大正则化参数值 评估假设函数Evaluating a Hypothesis 如何判断过拟合？ 随机将数据分为两部分，一部分是训练集，一部分是预测集（30%） 学习训练集的参数θ（即最小化训练误差J ） 计算测试集误差 线性回归中计算测试集的 J(θ) 逻辑回归中可以用误分类率来计算error： $err(h_\\theta(x),y)=\\begin{cases}1,&amp;if\\ h_\\theta(x)\\ge 0.5,y=0\\ or\\ if\\ h_\\theta(x)&lt;0.5, y=1\\\\0, &amp;otherwise\\end{cases}$ $Test\\ error=\\frac{1}{m_{test}}\\sum\\limits_{i=1}^{m_{test}}err(h_\\theta(x_{test}^{(i)},y^{(i)}))$ 模型选择问题：确定对于某组数据最合适的多项式是几次，怎样选用正确的特征来构造学习算法，或者需要正确选择算法中的正则化参数λ 将数据分为三段：训练集（60%），交叉验证集（cross validation）（20%），测试集（20%） 用不同的多项式模型得到θ，然后计算交叉验证集的误差，看看哪个模型中CV集的误差最小，进而选择那个多项式模型 最后计算测试集误差评价模型表现 Bias vs. Variance 分析bias和variance 高偏差：欠拟合；高方差：过拟合 高偏差： $J_{train}(\\theta)$will be high, the same as $J_{CV}(\\theta)\\approx J_{train}(\\theta)$ 高方差： $J_{train}(\\theta)$will be low, $J_{CV}(\\theta)\\gg J_{train}(\\theta)$ 正则化与方差、偏差的关系 正则化可以有效防止过拟合 选择λ的过程： Create a list of lambdas (i.e. λ∈{0,0.01,0.02,0.04,0.08,0.16,0.32,0.64,1.28,2.56,5.12,10.24}); Create a set of models with different degrees or any other variants. Iterate through the λs and for each λ go through all the models to learn some Θ. Compute the cross validation error using the learned Θ (computed with λ) on the$ J_{CV}(\\Theta)$ without regularization or λ = 0. Select the best combo that produces the lowest error on the cross validation set. Using the best combo Θ and λ, apply it on$ J_{test}(\\Theta)$ to see if it has a good generalization of the problem. 注：训练时带λ，计算各个集的误差时不需要λ，即$J_{train}(\\theta)$、$J_{CV}(\\theta)$、$J_{test}(\\theta)$都不包含正则项 J_{train}(\\theta)=\\frac {1}{2m}\\sum \\limits_{i=1}^m(h_\\theta(x^{(i)})-y^{(i)})^2 学习曲线（error-训练集的大小） 高偏差 Low training set size: causes $J_{train}(\\Theta)$ to be low and $J_{CV}(\\Theta)$ to be high. Large training set size: causes both $J_{train}(\\Theta)$ and $J_{CV}(\\Theta)$ to be high with $J_{train}(\\Theta)≈J_{CV}(\\Theta)$. 高偏差，更多训练数据不会有很大帮助 高方差 Low training set size: causes $J_{train}(\\Theta)$ to be low and $J_{CV}(\\Theta)$ to be high. Large training set size: $J_{train}(\\Theta)$ increases with training set size and $J_{CV}(\\Theta)$ continues to decrease without leveling off. Also, $J_{train}(\\Theta) &lt; J_{CV}(\\Theta)$ but the difference between them remains significant. 高方差，更多训练数据可能有帮助 诊断法则如何判断 更多训练数据——高方差，画学习曲线 更少特征集避免过拟合——高方差 更多特征——高偏差 增加多项式特征——高偏差 减少（高偏差）或增大正则化参数值（高方差） 正则化会保留所有的特征变量，但是会减小特征变量的数量级。正则化就是使用惩罚项，通过惩罚项，我们可以将一些参数的值变小。通常参数值越小，对应的函数也就越光滑，也就是更加简单的函数，因此不容易发生过拟合问题。 神经网络很容易过拟合，正则化项非常有用 如何选择几层隐藏层： 通过交叉验证集，测试1，2，…，l个隐藏层的误差，选择表现最好的一个 Build a Spam Classifier 做法： 遍历整个训练集，然后在中间选出出现次数最多的n个单词，n一般介于10000和50000之间，作为特征 列出可能的做法，讨论可行性，然后选择一个方向 误差分析 推荐做法： 用简单算法快速实现，然后测试CV集（避免过早优化） 画学习曲线，决定是否需要更多数据、更多特征或其他 误差分析：手动检验CV集中的错误分类样本，发现系统性的错误分类特征，构造更好的特征 手动对错误的部分分类 发现特征 用数字来量化表现误差（在CV集上，不能在test集上） stem词干提取（porter stemmer） skewed classes 偏斜类问题 癌症的比例非常非常低 查准率（precision）：预测为1的病人里，多少是真正得癌症的 $=\\frac{True\\ positives}{predicted\\ positives}=\\frac{True\\ positives}{True\\ pos+False\\ pos}$ 召回率Recall：实际得癌症的病人里，多少是真正预测得癌症的 $=\\frac{True\\ positives}{actual\\ positives}=\\frac{True\\ positives}{True\\ pos+False\\ neg}$ 假设现在想要预测y=1，当非常自信的情况下（修改$h_\\theta(x)$分类临界值threshold0.5为0.9）：高查准，低召回 假设想要避免错过癌症案例，（修改$h_\\theta(x)$分类临界值0.5为0.3）：高召回，低查准 绘制查准率-召回率曲线 $F_1$Score $=\\frac{2PR}{P+R}$: 评估选择算法或者不同临界值的量化标准 Data For Machine Learning 有大量训练数据可以显著提升算法表现，可能得到低方差、低偏差的结果，test误差和train误差也相近 多项式参数对大训练集没有帮助","link":"/Machine-Learning-Week06/"},{"title":"Machine Learning Week07","text":"Support Vector Machines 支持向量机Large Margin Classification Optimization Objective 优化目标 在复杂非线性方程的学习上有优势。 注：实际上在训练代价函数时，分界线为-1，1 Large Margin Intuition 代价函数： \\min _{\\theta} C \\sum_{i=1}^{m}\\left[y^{(i)} {\\operatorname{cost}_{1}\\left(\\theta^{T} x^{(i)}\\right)}+\\left(1-y^{(i)}\\right) \\operatorname{cost}_{0}\\left(\\theta^{T} x^{(i)}\\right)\\right]+\\frac{1}{2} \\sum_{i=1}^{n} \\theta_{j}^{2}\\\\ if\\ y=1, we\\ want\\ \\theta^{T} x \\geq 1\\ (not\\ just \\left.\\geq 0\\right)\\\\ if\\ y=0, we\\ want\\ \\theta^{T} x \\leq-1\\ (not\\ just","link":"/Machine-Learning-Week07/"},{"title":"Machine Learning Week09","text":"Anomaly Detection 异常检测Density EstimationProblem Motivation异常检测主要用于unsupervised learning Model：$P(x_{test}&lt;\\epsilon)\\rightarrow anomaly$ ​ $P(x_{test}\\ge \\epsilon)\\rightarrow OK$ 也被用于检测账号被盗、生产、数据中心的电脑 Gaussian Distribution=Normal distribution X ～ N (0, 1)，“distributed as”, 这里N的符号为”script N” 给定dataset，参数估计：via Maximum likelihood estimation 通常是m-1，对大数据集没影响 \\mu = \\frac{1}{m}\\sum_{i=1}^mx^{(i)}\\\\ \\sigma^2=\\frac{1}{m}\\sum_{i=1}^m(x^{(i)}-\\mu)^2Algorithm基本假设，各特征间相互独立 P(x)=\\prod_{j=1}^np(x_j;\\mu_j,\\sigma_j^2) Building an Anomaly Detection SystemDeveloping and Evaluating an Anomaly Detection SystemTraining set: normal examples (可以有少量异常的混进来) 然后应用于cross calidation set 和 test set 10000正常，20异常： ​ 训练集：6000正常 ​ CV：2000正常，10异常 ​ Test：2000正常，10异常 由于normal是0，所以预测0常常有更高的准确率，是skew的偏斜的。因此查准率accuracy不是很好的分析指标。 选择ε时，可以试几个不同的，然后选择使得Cross validation集中F1-score最大的，或者效果最好的。 有时还需要决定用什么特征 Anomaly detection vs. Supervised learningAnomaly detection: y=1非常少(0-20常见), y=0占比更大 有大量不同的异常类型，其他算法难于分辨各种类型 有未知异常类型 supervised learning： 大量的positive 和negative examples 有足够positive examples，并且未来的positive example和训练集的相似 Spam Choosing what features to use Non-gaussian feature 绘制特征的直方图，看是否大致是个bell shaped curve，如果不是，运用一些变换使得其看起来更加gaussian Error analysis for anomaly detection 甄别失败时，new feature 可能有帮助，例如组合现有的特征形成新特征 Multivariate Gaussian DistributionMultivariate Gaussian Distribution不同于之前的是，p(x)不再是各个特征概率的乘积。 Parameters: $\\mu \\in \\R^n$, $\\Sigma \\in \\R^{n\\times n}$ p(x;\\mu,\\Sigma)= \\frac{1}{(2\\pi)^{\\frac{n}{2}}|\\Sigma|^2}exp(-\\frac{1}{2}(x-\\mu)^T\\Sigma^{-1}(x-\\mu))$|\\Sigma|$=determinant of Σ \\mu = \\frac{1}{m}\\sum_{i=1}^mx^{(i)}\\\\ \\Sigma = \\frac{1}{m}\\sum_{i=1}^m(x^{(i)}-\\mu)(x^{(i)}-\\mu)^TAnomaly Detection using the multivariate Gaussian distribution首先计算μ和Σ，然后计算p(x)，最后根据ε判断是否异常 优点：自动捕捉特征间的相关性。m&gt;10n用起来才比较好，必须要m&gt;n，否则协方差矩阵不可逆。 缺点：计算量比较大。如果某个特征是其他的线性组合，那么协方差矩阵也不可逆，要注意避免。 前述的模型：优点在于计算量小，但是要人工创造一些新特征来更好地分辨。m&lt;n的时候也能用。 若出现协方差矩阵不可逆： 首先检查m, n大小 检查是否有redundant features，就是特征间是否线性独立 Predicting Movie Ratings ——Recommendation SystemProblem Formulationr(i,j) 表示第i个电影，j用户是否打分； y(i,j) 表示该用户对该电影的打分值 ； Content Based Recommendations设电影特征n个 For each user j, learn a parameter $\\theta^{(j)}\\in\\R^{n+1}$. Predict user j as rating movie i with $(\\theta^{(j)})^Tx^{(i)}$ stars. （注意 $x_0=1$）。用线性回归 To learn $\\theta^{(j)}$： \\min_{\\Theta^{(j)}}\\frac{1}{2m^{(j)}}\\sum_{i:r(i,j)=1}((\\theta^{(j)})^Tx^{(i)}-y^{(i,j)})^2+\\frac{\\lambda}{2m^{(j)}}\\sum_{k=1}^{n}(\\theta_k^{(j)})^2Note: 这里 $m^{(j)}$可以去掉，对结果没有任何影响 优化目标也可以为： J(\\Theta^{(1)},...,\\Theta^{(n_u)})=\\min_{\\Theta^{(1)},...,\\Theta^{(n_u)}}\\frac{1}{2}\\sum_{j=1}^{n_u}\\sum_{i:r(i,j)=1}((\\theta^{(j)})^Tx^{(i)}-y^{(i,j)})^2+\\frac{\\lambda}{2}\\sum_{j=1}^{n_u}\\sum_{k=1}^{n}(\\theta_k^{(j)})^2Gradient descent update: \\theta_{k}^{(j)}:=\\theta_{k}^{(j)}-\\alpha \\sum_{i: r(i, j)=1}\\left(\\left(\\theta^{(j)}\\right)^{T} x^{(i)}-y^{(i, j)}\\right) x_{k}^{(i)}\\ (\\text { for } k=0) \\theta_{k}^{(j)}:=\\theta_{k}^{(j)}-\\alpha\\left(\\sum_{i: r(i, j)=1}\\left(\\left(\\theta^{(j)}\\right)^{T} x^{(i)}-y^{(i, j)}\\right) x_{k}^{(i)}+\\lambda \\theta_{k}^{(j)}\\right)\\ (\\text { for } k \\neq 0)k=0的时候不加正则项 Collaborative FilteringCollaborative Filtering feature learning Given $\\Theta^{(1)},…,\\Theta^{(n_u)}$，to learn $x^{(1)},…,x^{(n_m)}$; 算法类似7、8式 $用户的\\Theta\\rightarrow 电影特征x\\rightarrow \\Theta\\rightarrow x\\rightarrow…$ 每个用户都在帮助这个推荐系统更好地分类电影，从而更好地预测评分 算法：同时实现： Given $x^{(1)},…,x^{(n_m)}$，estimate $\\theta^{(1)},…,\\theta^{(n_u)}$： \\min_{\\Theta^{(j)}}\\frac{1}{2m^{(j)}}\\sum_{i:r(i,j)=1}((\\theta^{(j)})^Tx^{(i)}-y^{(i,j)})^2+\\frac{\\lambda}{2m^{(j)}}\\sum_{k=1}^{n}(\\theta_k^{(j)})^2 Given $\\theta^{(1)},…,\\theta^{(n_u)}$，estimate $x^{(1)},…,x^{(n_m)}$： \\min _{x^{(1)}, \\ldots, x^{\\left(n_{m}\\right)}} \\frac{1}{2} \\sum_{i=1}^{n_{m}} \\sum_{j: r(i, j)=1}\\left(\\left(\\theta^{(j)}\\right)^{T} x^{(i)}-y^{(i, j)}\\right)^{2}+\\frac{\\lambda}{2} \\sum_{i=1}^{n_{m}} \\sum_{k=1}^{n}\\left(x_{k}^{(i)}\\right)^{2} 即： Minimizing $x^{(1)},…,x^{(n_m)}$ and $\\theta^{(1)},…,\\theta^{(n_u)}$ simultaneously： \\min_{x^{(1)},...,x^{(n_m)}\\\\\\theta^{(1)},...,\\theta^{(n_u)}}J\\left(x^{(1)}, \\ldots, x^{\\left(n_{m}\\right)}, \\theta^{(1)}, \\ldots, \\theta^{\\left(n_{u}\\right)}\\right) J\\left(x^{(1)}, \\ldots, x^{\\left(n_{m}\\right)}, \\theta^{(1)}, \\ldots, \\theta^{\\left(n_{u}\\right)}\\right)=\\frac{1}{2} \\sum_{(i, j): r(i, j)=1}\\left(\\left(\\theta^{(j)}\\right)^{T} x^{(i)}-y^{(i, j)}\\right)^{2}+\\frac{\\lambda}{2} \\sum_{i=1}^{n_{m}} \\sum_{k=1}^{n}\\left(x_{k}^{(i)}\\right)^{2}+\\frac{\\lambda}{2} \\sum_{j=1}^{n_{u}} \\sum_{k=1}^{n}\\left(\\theta_{k}^{(j)}\\right)^{2} 该算法下，无需设定 $x_0=1$, 也没有$\\theta_0$，因为算法会自行选择参数。该算法下：$\\theta\\in\\R^n$，$x\\in\\R^n$，n是特征数 算法实现： Initialize $x^{(1)},…,x^{(n_m)}$， $\\theta^{(1)},…,\\theta^{(n_u)}$ to small random values Minimize J using gradient descent (or an advanced optimization algorithm) For a user with parameters $\\theta$ and a movie with (learned) features x, predict a star rating of $\\theta^Tx$ Low Rank Matrix FactorizationVectorization Given matrices X (each row containing features of a particular movie) and Θ (each row containing the weights for those features for a given user), then the full matrix Y of all predicted ratings of all movies by all users is given simply by: $Y = X\\Theta^T$. Predicting how similar two movies i and j are can be done using the distance between their respective feature vectors x. Specifically, we are looking for a small value of $||x^{(i)} - x^{(j)}||$. Mean NormalizationIf the ranking system for movies is used from the previous lectures, then new users (who have watched no movies), will be assigned new movies incorrectly. Specifically, they will be assigned θ with all components equal to zero due to the minimization of the regularization term. That is, we assume that the new user will rank all movies 0, which does not seem intuitively correct. 新用户会被预测为0 We rectify this problem by normalizing the data relative to the mean. First, we use a matrix Y to store the data from previous ratings, where the ith row of Y is the ratings for the ith movie and the jth column corresponds to the ratings for the jth user. We can now define a vector \\mu = [\\mu_1, \\mu_2, \\dots , \\mu_{n_m}]such that \\mu_i = \\frac{\\sum_{j:r(i,j)=1}{Y_{i,j}}}{\\sum_{j}{r(i,j)}}Which is effectively the mean of the previous ratings for the ith movie (where only movies that have been watched by users are counted). We now can normalize the data by subtracting u, the mean rating, from the actual ratings for each user (column in matrix Y): As an example, consider the following matrix Y and mean ratings μ: Y=\\left[\\begin{array}{cccc} 5 & 5 & 0 & 0 \\\\ 4 & ? & ? & 0 \\\\ 0 & 0 & 5 & 4 \\\\ 0 & 0 & 5 & 0 \\end{array}\\right], \\quad \\mu=\\left[\\begin{array}{c} 2.5 \\\\ 2 \\\\ 2.25 \\\\ 1.25 \\end{array}\\right]The resulting Y′ vector is: Y^{\\prime}=\\left[\\begin{array}{cccc} 2.5 & 2.5 & -2.5 & -2.5 \\\\ 2 & ? & ? & -2 \\\\ -2 .25 & -2.25 & 3.75 & 1.25 \\\\ -1.25 & -1.25 & 3.75 & -1.25 \\end{array}\\right]Now we must slightly modify the linear regression prediction to include the mean normalization term: (\\theta^{(j)})^T x^{(i)} + \\mu_iNow, for a new user, the initial predicted values will be equal to the μ term instead of simply being initialized to zero, which is more accurate. Note: 一般的均值归一化要除以range，即max-min，但是这里不需要，因为都有统一的scale","link":"/Machine-Learning-Week09/"},{"title":"Machine Learning Week08","text":"Unsupervised learning 无监督学习Clustering 聚类无监督学习是不给分类标签y 1. 应用： 对消费者市场划分 社交网络分析 管理计算机 获取星系信息 2. K-means algorithm K均值算法 随机选择两个点作为聚类中心(分两类)，然后进行下面两步 簇分配，遍历每个点，和哪个cluster centroid更近 移动聚类中心到上面分配的簇的均值 Input: K - number of clusters training set algorithm 123456 repeat{ for i=1 to m c_i := index (from 1 to K) of cluster centroid closest to x_i for k=1 to K u_k := average (mean) of points assigned to cluster k} 如果有中心没有被分配到任何点，可以删去这个分类，也可以reinitialize the cluster centroid 3. K-means for non-sperated clusters 根据身高体重分类T恤大小 4. Optimization Objective \\begin{array}{l} J\\left(c^{(1)}, \\ldots, c^{(m)}, \\mu_{1}, \\ldots, \\mu_{K}\\right)=\\frac{1}{m} \\sum_{i=1}\\left\\|x^{(i)}-\\mu_{c^{(i)}}\\right\\|^{2} \\\\ \\min _{c^{(1)}, \\ldots, c^{(m)},\\mu_{1}, \\ldots, \\mu_{K}} J\\left(c^{(1)}, \\ldots, c^{(m)}, \\mu_{1}, \\ldots, \\mu_{K}\\right) \\end{array} also called distortion of K-means algorithm cost function 关于iteration的曲线 5. Random Initialization随机初始化聚类中心 随机选k个个例本身，作为中心，但是容易陷入Local optima。解决方案：多次随机，选择cost function最小的 6. Choosing the Number of ClustersElbow Method: 绘制J关于K的曲线，找到“Elbow”的节点，作为分类个数 用途之一：later/downstream purpose Motivation1. Data Compression —— Dimensionality Reduction降维压缩数据，减少内存占用加快运算 2. Data Visualization降维可以便于数据可视化 Principal Component Analysis主成分分析1. Problem formulationPCA：To find a surface onto which to project the data so as to minimize the the projection error (线性拟合中就是使得离某条直线的距离最小). 先mean normalization（feature scaling） Reduce from 2-dimension to 1-dimension: Find a direction (a vector $u_i\\in \\R^n$) onto which to project the data so as to minimize the projection error. 该向量的正负没有关系。 Reduce from n-dimension to k-dimension: Find k vectors $u^{(1)}$,$u^{(2)}$, … , $u^{(k)}$ onto which to project the data so as to minimize the projection error. 注：PCA is not linear regression。注意看下图区别，线性回归是和预期值的差最小，PCA是到直线距离最小 2. PCA AlgorithmPCA的目标： maximize variance perspective 最大投影方差 minimize error perspective 最小重构代价 Step1: mean normalization. 根据数据(有不同的scales)，可能还需要feature scaling。均值归一化是特征缩放的一种方法。（除以标准差） Step2: Reduce data from n-dimensions to k-dimensions： Compute “covariance matrix”: $\\Sigma = \\frac{1}{m}\\sum_{i=1}^{n}{(x^{(i)})(x^{(i)})^T}$，xi是n*1的列向量，symmetric positive definite Compute “eigenvectors” of matrix $\\Sigma$: [U, S, V] = svd(Sigma) ;或者 eig(Sigma) svd: Singular value decomposition 奇异值分解 其中U是我们需要的， 列向量为各个特征向量，压缩到k个向量只需要取前k个列向量（对称矩阵的特征向量是正交的） 注：PCA算法中，没有x0=1这一项 疑问： 为什么不直接用X进行SVD，而要算协方差的SVD？ Answer：协方差的U和X的V是相等的，其实都可以 理解：$X=U’S’V’^T$, $X^TX=USV^T$，现要说明 $V’=U$, 只需要 $X^TX=V’S’^2V’^T=USV^T$，所以 $V’=U$。 为什么要取协方差矩阵SVD后的左奇异矩阵来压缩特征维度？ 首先易证一个SPD矩阵通过SVD得到的U和V是相等的。 其次，通常我们用XV=YU来表示坐标变换。 $\\Sigma = X^TX$，又有 $\\Sigma = USV^T$，可以得到 $\\Sigma V = US$，这里实际上是将covariance矩阵变化为对角线矩阵，即互不相关（其中U=V，即U为协方差矩阵的特征向量，S为其特征值）。那么这时，我们令XI=UZ，I是X坐标系下的正交基，即 $Z=U^TX$。此时Z的协方差 $Z^TZ=\\Sigma$。 Applying PCAReconstruction from compressed representation z=U_{reduce}^Tx可以得到： x_{approx}=U_{reduce}zChoosing the number k of principal component Average squared projection error： \\frac{1}{m}\\Sigma_{i=1}^m\\parallel x^{(i)}-x_{approx}^{(i)}\\parallel ^2 Tptal variation in the data: \\frac{1}{m}\\Sigma_{i=1}^m\\parallel x^{(i)}\\parallel ^2 Choose k to be smallest value so that \\frac{\\frac{1}{m}\\Sigma_{i=1}^m\\parallel x^{(i)}-x_{approx}^{(i)}\\parallel ^2}{\\frac{1}{m}\\Sigma_{i=1}^m\\parallel x^{(i)}\\parallel ^2}\\le0.01“99% of variance is retained”。这个数值可以根据需求不同更换。 算法： SVD函数返回的S矩阵为diagonal matrix。 For given k: k 递增，使得 1-\\frac{\\Sigma_{i=1}^{k}S_{ii}}{\\Sigma_{i=1}^{n}S_{ii}}\\le0.01选择最小的K满足上式。 根据性质：矩阵特征值之和等于主对角线元素之和，易证(6)式等价于(7)式。 Advice for applying PCA Supervised learning speedup 压缩原始训练集数据的维度 Mapping $x^{(i)}\\rightarrow z^{(i)}$should be defined by running PCA only on the trainning set. This mapping can be applied as well to the examples $x_{CV}^{(i)}$ and $x_{test}^{(i)}$ in the cross validation and test sets. Compression Reduce memory/disk needed to store data speed up learning algorithm Visualization Bad use of PCA: To prevent overfitting 可能确实可以避免过拟合，但是不是解决过拟合的好方法。正确方法式加正则项(Use regularization instead!) For example: 正确做法是先不用PCA，在原始数据跑一遍，如果不符合期望，再用PCA","link":"/Machine-Learning-Week08/"},{"title":"My Application Review","text":"31b86f4658a1544a28b7adc265148c745206c7c6db9bbde9f2f8c24c61116226 Hello~You have to input the right password.","link":"/My-Application-Review/"},{"title":"","text":"1. Machine LearningStep 1 [ ] Hands-On Machine learning with Scikit-Learn and Tensorflow [ ] Python Machine Learning. Sebastian Raschka [ ] Introduction to Statistical Learning with R [ ] 【参考书】机器学习. 周志华 Step 2 [ ] 训练平台：Kaggle，天池大数据竞赛 [ ] Scikit-learn: machine learning in Python Step 3 [ ] Deeplearning.ai —— Coursera [ ] Deep learning - by Ian GoodFellow Step 4 [ ] Elements of Statistical Learning [ ] 统计学习基础 [ ] 订阅arxiv [ ] 关注顶会：ICML/NIPS/KDD 2. Financial Engineering金融工程专业需要哪些数学基础？ - 经管之家的回答 - 知乎","link":"/Reading-List/"},{"title":"Hello World","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","link":"/hello-world/"},{"title":"This is my first blog!","text":"This is the first time for me to use Hexo to build my blog. My major is Engineering Physics and Financial Engineering. Hope to share my experiences with you! Thank you for following my blog!","link":"/This-is-my-first-bolg/"},{"title":"Machine Learning Week10","text":"Large Scale Machine LearningGradient Descent with Large DatasetsLearning with large datasets如何知道小m（size of dataset）也能产生很好的结果？绘制learning curve（error关于m的曲线） 左图为high variance，说明增加m有助于结果变好；右图为high bias，说明增加m无助于结果变好 Stochastic gradient descent 随机梯度下降Batch gradient descent: 前述传统的梯度下降算法。batch意味着每次都要用到所有m个例子 Stochastic gradient descent：每次iteration用1个例子 Randomly shuffle dataset Repeat： for i =1,…, m { $\\theta_j=\\theta_j-\\alpha(h_{\\theta}(x^{(i)})-y^{(i)})x_j^{(i)}$ } Note: 和Batch gradient descent不同的是，无需每一步都要计算全部的training example 并不一定会达到global minimum，最后可能在全局最优附近徘徊。 上述过程重复的次数取决于数据集的大小，一般为10次，若数据集特别大，则1次。 Mini-Batch gradient descent每次iteration用b（mini-batch size）个例子，常用2-100 第i个例子，直到第i+b-1个例子 只有当have a good vetorized implementation ，mini-batch才能比stochastic表现得更好。（并行运算） Stochastic gradient descent convergence收敛性： 更小的学习速率学习曲线更平滑，有可能会得到slightly better结果。（cost关于no. of iteration 的曲线） 增加1000这个数值，会使得曲线更加平滑 如果学习曲线在上升，就要用更小的α 如果学习曲线几乎在一个水平上，那么就需要增加特征等 关于学习速率的选择： Learning rate α is typically held constant 在随机梯度下降中 Can slowly decrease α over time if we want θ to converge. （例如：$\\alpha=\\frac{const1}{iteration Number+const2}$） 但是这里，两个参数的调整tune会很费时间，所以很少采用这种方法 Advanced TopicsOnline Learning 连续的数据流：用户进入离开 $p(y=1|x;\\theta)$其中x表示价格，可以用logistic regression或者神经网络 这里考虑逻辑回归： Repeat forever { ​ Get (x,y) corresponding to user. ​ Update θ using (x,y): ​ $\\theta_j:=\\theta_j-\\alpha(h_{\\theta}(x)-y)x_j$ (j=0, …, n) } 这个算法可以用于学习用户喜好 Choosing special offers to show user Customized selection of news articles product recommendation/search Map reduce and data parallelismMap reduce 可以处理更多数据。思想来自于Jeffrey Dean和Sanjay Ghemawat。summation over the training set。即并行处理 神经网络也同样可以并行计算前向和后向propagation 有时只需要向量化实现算法，不需要多核并行 Hadoop是开源map reduce 由于并行的latency，速度会少于N倍 的单核心","link":"/Machine-Learning-Week10/"}],"tags":[{"name":"Learning Tips","slug":"Learning-Tips","link":"/tags/Learning-Tips/"},{"name":"Issues","slug":"Issues","link":"/tags/Issues/"},{"name":"Machine Learning","slug":"Machine-Learning","link":"/tags/Machine-Learning/"},{"name":"Private","slug":"Private","link":"/tags/Private/"},{"name":"Essay","slug":"Essay","link":"/tags/Essay/"}],"categories":[]}